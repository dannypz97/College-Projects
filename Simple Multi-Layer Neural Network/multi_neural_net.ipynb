{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Simple project with the aim of creating a basic multi-layer neural net using only numpy.'''\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class NeuralNet():\n",
    "    \n",
    "    def __init__(self,neurons_per_layer = [1,4,4,1], eta = 0.2, epochs = 2000000,activations = [\"sigmoid\",\"sigmoid\",\"sigmoid\"]):\n",
    "        \n",
    "        self.neurons_per_layer = neurons_per_layer\n",
    "        self.size = len(neurons_per_layer)-1 #size of A.N.N. (1st layer is input layer so ignore)\n",
    "        self.eta = eta \n",
    "        self.epochs = epochs\n",
    "        self.activations = activations\n",
    "        self.W = [] #to store layerwise weights \n",
    "        self.b = [] #to store layerwise biases\n",
    "        self.A = [] #to cache layerwise activation values\n",
    "        self.Z = [] #to cache layerwise Z values\n",
    "        self.dW = [] #store layerwise gradients for W \n",
    "        self.db = [] #store layerwise gradients for b\n",
    "        self.lambd = 0\n",
    "        \n",
    "    def setup_params(self):  #setup the weights and biases for each layer\n",
    "        for l in range(1, self.size+1):\n",
    "            self.W.append(np.random.rand(self.neurons_per_layer[l], self.neurons_per_layer[l-1]))\n",
    "            self.b.append(np.zeros((self.neurons_per_layer[l], 1)))\n",
    "        \n",
    "        \n",
    "    def train(self,X,Y,type=\"normal\", mini_batch_size = 1, regularization=None):\n",
    "        self.setup_params() \n",
    "        self.m = len(X) #no. of training examples \n",
    "        self.regularization = regularization #None,\"L2\"\n",
    "        \n",
    "        if self.regularization == \"L2\":\n",
    "            self.lambd = 0.01\n",
    "            \n",
    "        if type==\"normal\":            \n",
    "            self.X = X.T\n",
    "            self.Y = Y\n",
    "            for iters in range(self.epochs):\n",
    "                Al = self.forward_prop(self.X)\n",
    "                self.J = self.compute_cost(Al)\n",
    "                db, dW = self.back_prop()\n",
    "                self.gradient_descent(db, dW)\n",
    "                if iters/5000 - iters//5000 == 0:\n",
    "                    print(\"Cost at {0} iterations is {1}\".format(iters,self.J))\n",
    "            print(\"Cost at {0} iterations is {1}\".format(iters,self.J))\n",
    "        \n",
    "        if type==\"minibatch\":\n",
    "            if mini_batch_size==1:\n",
    "                type=\"stochastic\"\n",
    "            else:\n",
    "                print(len(X),\" \",len(Y[0]))\n",
    "                X = np.array_split(X,math.ceil(len(X)/mini_batch_size), axis=0)\n",
    "                Y = np.array_split(Y,math.ceil(len(Y[0])/mini_batch_size), axis=1)\n",
    "                for iters in range(self.epochs):\n",
    "                    for i in range(len(X)):\n",
    "                        if len(X[i]) > 0:\n",
    "                            \n",
    "                            self.X = X[i].T\n",
    "                            self.Y = Y[i]\n",
    "                            Al = self.forward_prop(self.X)\n",
    "                            self.J = self.compute_cost(Al)\n",
    "                            db, dW = self.back_prop()\n",
    "                            self.gradient_descent(db, dW)\n",
    "                            if iters/50000 - iters//50000 == 0:\n",
    "                                print(\"Cost at {0} iterations is {1}\".format(iters,self.J))\n",
    "                print(\"Cost at {0} iterations is {1}\".format(iters,self.J))\n",
    "        \n",
    "                \n",
    "        if type==\"stochastic\":\n",
    "            for iters in range(self.epochs):\n",
    "                for i in range(self.m):\n",
    "                    self.X = X.T[:, i:i+1]\n",
    "                    self.Y = Y[:,i:i+1]\n",
    "                    Al = self.forward_prop(self.X)\n",
    "                    self.J = self.compute_cost(Al)\n",
    "                    db, dW = self.back_prop(Al)\n",
    "                    self.gradient_descent(db, dW)\n",
    "                    if iters/5000 - iters//5000 == 0:\n",
    "                        print(\"Cost at {0} iterations is {1}\".format(iters,self.J))\n",
    "            print(\"Cost at {0} iterations is {1}\".format(iters,self.J))\n",
    "       \n",
    "        if type==\"grad_check\":  #compute numerical and analytical gradients to check if backprop working correctly.\n",
    "            self.X = X.T\n",
    "            self.Y = Y\n",
    "            for iters in range(1):\n",
    "                self.grad_check()\n",
    "    \n",
    "    def forward_prop(self, X):\n",
    "        A = X\n",
    "        self.Z = []\n",
    "        self.A = [A]\n",
    "        for l in range(0, self.size):\n",
    "            Z = np.dot(self.W[l], A) + self.b[l]\n",
    "            if self.activations[l] == \"sigmoid\": #if hidden layer\n",
    "                A = self.sigmoid(Z)\n",
    "            elif self.activations[l] == \"relu\":\n",
    "                A = self.relu(Z)\n",
    "            elif self.activations[l] == \"tanh\":\n",
    "                A = self.tanh(Z)\n",
    "            self.Z.append(Z)\n",
    "            self.A.append(A)\n",
    "        return A\n",
    "    \n",
    "    def back_prop(self):\n",
    "        dW = []\n",
    "        db = []\n",
    "        dA = -1*(self.Y/self.A[-1]) + (1-self.Y)/(1-self.A[-1])\n",
    "        dA = 2*(self.A[-1]-self.Y)\n",
    "        for l in range(self.size-1, -1, -1):\n",
    "            if self.activations[l]==\"sigmoid\":                \n",
    "                dZ = dA * self.sigmoid_prime(self.Z[l])\n",
    "            elif self.activations[l]==\"tanh\":\n",
    "                dZ = np.multiply(dA, self.tanh_prime(self.Z[l]))\n",
    "            elif self.activations[l]==\"relu\":\n",
    "                dZ = np.multiply(dA, self.relu_prime(self.Z[l]))\n",
    "\n",
    "            dwL = (np.dot(dZ,self.A[l].T))/self.m + self.lambd/self.m*self.W[l]\n",
    "            dbL = np.sum(dZ, axis=1, keepdims = True)/self.m\n",
    "            \n",
    "            dA = np.dot(self.W[l].T, dZ)\n",
    "            dW.insert(0,dwL)\n",
    "            db.insert(0,dbL)\n",
    "        return db, dW\n",
    "    \n",
    "    def gradient_descent(self, db, dW):\n",
    "        for l in range(0, self.size):\n",
    "            self.W[l] -= self.eta*(dW[l])\n",
    "            self.b[l] -= self.eta*(db[l])\n",
    "            \n",
    "    def compute_cost(self, Al):\n",
    "        cost = np.sum(-1*(self.Y*np.log(Al) + (1-self.Y)*np.log(1-Al)))/self.m    #cross entropy \n",
    "        cost = np.square(Al-self.Y).sum()/self.m\n",
    "        if self.regularization == \"L2\":\n",
    "            l2 = 0\n",
    "            for l in range(0,self.size):\n",
    "                l2 += np.sum(np.square(self.W[l]))\n",
    "            l2 = self.lambd/(2*self.m) * l2\n",
    "            cost += l2\n",
    "        return cost\n",
    "    \n",
    "    def sigmoid(self, Z):\n",
    "        return 1/(1+np.exp(-Z))\n",
    "    \n",
    "    def relu(self, Z):\n",
    "        return np.maximum(Z,0,Z)\n",
    "    \n",
    "    def tanh(self, Z):\n",
    "        return (np.exp(Z)-np.exp(-Z))/(np.exp(Z)+np.exp(-Z))\n",
    "        \n",
    "    def sigmoid_prime(self, Z):\n",
    "        return self.sigmoid(Z) * (1-self.sigmoid(Z))\n",
    "    \n",
    "    def relu_prime(self,Z):\n",
    "        return np.where(Z>0,1.0,np.where(Z==0,0.05,0))\n",
    "        \n",
    "    def tanh_prime(self, Z):\n",
    "        return 1-np.square(self.tanh(Z),self.tanh(Z))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.forward_prop(X)\n",
    "    \n",
    "    def grad_check(self):        \n",
    "        epsilon = 1e-5\n",
    "        for l in range(self.size-1,-1,-1):\n",
    "            for i in range(len(self.W[l])):\n",
    "                theta = self.W[l]            \n",
    "                self.W[l] = theta+ epsilon\n",
    "                Al = self.forward_prop(self.X)\n",
    "                Jplus = self.compute_cost(Al)\n",
    "                \n",
    "                self.W[l] = theta - epsilon\n",
    "                Al = self.forward_prop(self.X)\n",
    "                Jminus = self.compute_cost(Al)\n",
    "                \n",
    "                approx_dW = (Jplus-Jminus)/(2.*epsilon)\n",
    "                print(\"1: layer{0} : {1}\".format(l+1,approx_dW))\n",
    "                \n",
    "                self.W[l] = theta\n",
    "                Al = self.forward_prop(self.X)\n",
    "                db, dW = self.back_prop()\n",
    "                print((dW[l]))\n",
    "                dW = np.ravel(dW[l])\n",
    "                \n",
    "                print(\"2: layer{0} : {1}\\n\".format(l+1,np.sum(dW)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at 0 iterations is 0.1310717389522621\n",
      "Cost at 5000 iterations is 0.002296906241812371\n",
      "Cost at 10000 iterations is 0.0019227436231382261\n",
      "Cost at 15000 iterations is 0.0018185726334933202\n",
      "Cost at 20000 iterations is 0.0017296958364130047\n",
      "Cost at 25000 iterations is 0.0016508500871946041\n",
      "Cost at 30000 iterations is 0.0015794963208841822\n",
      "Cost at 35000 iterations is 0.0015138573742518977\n",
      "Cost at 40000 iterations is 0.0014526651077714373\n",
      "Cost at 45000 iterations is 0.001395014516204131\n",
      "Cost at 50000 iterations is 0.0013402611940052176\n",
      "Cost at 55000 iterations is 0.0012879420700006563\n",
      "Cost at 60000 iterations is 0.001237713678021959\n",
      "Cost at 65000 iterations is 0.00118930949537656\n",
      "Cost at 70000 iterations is 0.0011425153897439303\n",
      "Cost at 75000 iterations is 0.0010971573651299658\n",
      "Cost at 80000 iterations is 0.0010530942652801332\n",
      "Cost at 85000 iterations is 0.0010102105533777977\n",
      "Cost at 90000 iterations is 0.0009684083516689675\n",
      "Cost at 95000 iterations is 0.0009276006948781948\n",
      "Cost at 100000 iterations is 0.0008877080424650708\n",
      "Cost at 105000 iterations is 0.0008486583556158429\n",
      "Cost at 110000 iterations is 0.0008103894061062034\n",
      "Cost at 115000 iterations is 0.0007728516131515141\n",
      "Cost at 120000 iterations is 0.0007360103515955826\n",
      "Cost at 125000 iterations is 0.0006998474689868039\n",
      "Cost at 130000 iterations is 0.0006643621518331453\n",
      "Cost at 135000 iterations is 0.0006295712967461209\n",
      "Cost at 140000 iterations is 0.0005955094025008384\n",
      "Cost at 145000 iterations is 0.0005622278786213459\n",
      "Cost at 150000 iterations is 0.000529793619989079\n",
      "Cost at 155000 iterations is 0.0004982867180007726\n",
      "Cost at 160000 iterations is 0.00046779725022968793\n",
      "Cost at 165000 iterations is 0.0004384212002646592\n",
      "Cost at 170000 iterations is 0.000410255692688521\n",
      "Cost at 175000 iterations is 0.00038339385992532045\n",
      "Cost at 180000 iterations is 0.0003579197543705291\n",
      "Cost at 185000 iterations is 0.0003339037503060579\n",
      "Cost at 190000 iterations is 0.00031139883223567865\n",
      "Cost at 195000 iterations is 0.00029043805056450035\n",
      "Cost at 200000 iterations is 0.00027103327289702497\n",
      "Cost at 205000 iterations is 0.0002531752067099592\n",
      "Cost at 210000 iterations is 0.00023683454593374925\n",
      "Cost at 215000 iterations is 0.0002219640141306823\n",
      "Cost at 220000 iterations is 0.0002085010405805864\n",
      "Cost at 225000 iterations is 0.0001963708045283481\n",
      "Cost at 230000 iterations is 0.0001854894065234688\n",
      "Cost at 235000 iterations is 0.00017576696457420496\n",
      "Cost at 240000 iterations is 0.00016711047913205393\n",
      "Cost at 245000 iterations is 0.00015942635890671793\n",
      "Cost at 250000 iterations is 0.00015262254479160846\n",
      "Cost at 255000 iterations is 0.00014661020859218127\n",
      "Cost at 260000 iterations is 0.00014130503484974968\n",
      "Cost at 265000 iterations is 0.00013662811708800855\n",
      "Cost at 270000 iterations is 0.00013250651455975798\n",
      "Cost at 275000 iterations is 0.00012887352307723685\n",
      "Cost at 280000 iterations is 0.00012566871523899737\n",
      "Cost at 285000 iterations is 0.00012283780291226488\n",
      "Cost at 290000 iterations is 0.0001203323696812058\n",
      "Cost at 295000 iterations is 0.00011810951437918255\n",
      "Cost at 300000 iterations is 0.00011613143974344651\n",
      "Cost at 305000 iterations is 0.0001143650133313812\n",
      "Cost at 310000 iterations is 0.00011278132153555487\n",
      "Cost at 315000 iterations is 0.00011135523205029504\n",
      "Cost at 320000 iterations is 0.00011006497555263335\n",
      "Cost at 325000 iterations is 0.00010889175364751892\n",
      "Cost at 330000 iterations is 0.00010781937721679989\n",
      "Cost at 335000 iterations is 0.00010683393710071388\n",
      "Cost at 340000 iterations is 0.00010592350741703055\n",
      "Cost at 345000 iterations is 0.00010507788067724148\n",
      "Cost at 350000 iterations is 0.0001042883330915757\n",
      "Cost at 355000 iterations is 0.0001035474179786398\n",
      "Cost at 360000 iterations is 0.00010284878493858988\n",
      "Cost at 365000 iterations is 0.00010218702235182143\n",
      "Cost at 370000 iterations is 0.00010155752078130112\n",
      "Cost at 375000 iterations is 0.00010095635494929043\n",
      "Cost at 380000 iterations is 0.00010038018210052456\n",
      "Cost at 385000 iterations is 9.982615473336161e-05\n",
      "Cost at 390000 iterations is 9.929184586278033e-05\n",
      "Cost at 395000 iterations is 9.877518516397872e-05\n",
      "Cost at 400000 iterations is 9.827440452537903e-05\n",
      "Cost at 405000 iterations is 9.778799171037385e-05\n",
      "Cost at 410000 iterations is 9.73146509855584e-05\n",
      "Cost at 415000 iterations is 9.685326971777476e-05\n",
      "Cost at 420000 iterations is 9.640289007285947e-05\n",
      "Cost at 425000 iterations is 9.59626850655529e-05\n",
      "Cost at 430000 iterations is 9.553193831329535e-05\n",
      "Cost at 435000 iterations is 9.511002693746151e-05\n",
      "Cost at 440000 iterations is 9.469640713502298e-05\n",
      "Cost at 445000 iterations is 9.429060201271997e-05\n",
      "Cost at 450000 iterations is 9.389219133569504e-05\n",
      "Cost at 455000 iterations is 9.350080289421492e-05\n",
      "Cost at 460000 iterations is 9.311610523651385e-05\n",
      "Cost at 465000 iterations is 9.273780155396199e-05\n",
      "Cost at 470000 iterations is 9.236562453732008e-05\n",
      "Cost at 475000 iterations is 9.199933205071011e-05\n",
      "Cost at 480000 iterations is 9.163870349364365e-05\n",
      "Cost at 485000 iterations is 9.12835367416035e-05\n",
      "Cost at 490000 iterations is 9.093364557280217e-05\n",
      "Cost at 495000 iterations is 9.058885750326401e-05\n",
      "Cost at 500000 iterations is 9.024901196465429e-05\n",
      "Cost at 505000 iterations is 8.991395876967257e-05\n",
      "Cost at 510000 iterations is 8.958355681862559e-05\n",
      "Cost at 515000 iterations is 8.92576730081775e-05\n",
      "Cost at 520000 iterations is 8.893618130955181e-05\n",
      "Cost at 525000 iterations is 8.861896198868619e-05\n",
      "Cost at 530000 iterations is 8.830590094532059e-05\n",
      "Cost at 535000 iterations is 8.799688915166804e-05\n",
      "Cost at 540000 iterations is 8.769182217451696e-05\n",
      "Cost at 545000 iterations is 8.739059976717144e-05\n",
      "Cost at 550000 iterations is 8.709312551992193e-05\n",
      "Cost at 555000 iterations is 8.679930655952248e-05\n",
      "Cost at 560000 iterations is 8.650905328976452e-05\n",
      "Cost at 565000 iterations is 8.622227916649429e-05\n",
      "Cost at 570000 iterations is 8.59389005015507e-05\n",
      "Cost at 575000 iterations is 8.56588362909727e-05\n",
      "Cost at 580000 iterations is 8.538200806364498e-05\n",
      "Cost at 585000 iterations is 8.510833974711428e-05\n",
      "Cost at 590000 iterations is 8.483775754793791e-05\n",
      "Cost at 595000 iterations is 8.457018984427798e-05\n",
      "Cost at 600000 iterations is 8.430556708889872e-05\n",
      "Cost at 605000 iterations is 8.404382172098707e-05\n",
      "Cost at 610000 iterations is 8.378488808552639e-05\n",
      "Cost at 615000 iterations is 8.352870235910396e-05\n",
      "Cost at 620000 iterations is 8.32752024812762e-05\n",
      "Cost at 625000 iterations is 8.302432809072135e-05\n",
      "Cost at 630000 iterations is 8.277602046556603e-05\n",
      "Cost at 635000 iterations is 8.253022246734808e-05\n",
      "Cost at 640000 iterations is 8.228687848818174e-05\n",
      "Cost at 645000 iterations is 8.204593440075049e-05\n",
      "Cost at 650000 iterations is 8.180733751083829e-05\n",
      "Cost at 655000 iterations is 8.157103651211832e-05\n",
      "Cost at 660000 iterations is 8.133698144299473e-05\n",
      "Cost at 665000 iterations is 8.110512364530655e-05\n",
      "Cost at 670000 iterations is 8.08754157247398e-05\n",
      "Cost at 675000 iterations is 8.06478115128164e-05\n",
      "Cost at 680000 iterations is 8.042226603034448e-05\n",
      "Cost at 685000 iterations is 8.019873545222365e-05\n",
      "Cost at 690000 iterations is 7.997717707353914e-05\n",
      "Cost at 695000 iterations is 7.975754927684791e-05\n",
      "Cost at 700000 iterations is 7.95398115006075e-05\n",
      "Cost at 705000 iterations is 7.932392420868613e-05\n",
      "Cost at 710000 iterations is 7.910984886089498e-05\n",
      "Cost at 715000 iterations is 7.889754788451112e-05\n",
      "Cost at 720000 iterations is 7.868698464671987e-05\n",
      "Cost at 725000 iterations is 7.847812342798526e-05\n",
      "Cost at 730000 iterations is 7.827092939626139e-05\n",
      "Cost at 735000 iterations is 7.806536858204597e-05\n",
      "Cost at 740000 iterations is 7.786140785423265e-05\n",
      "Cost at 745000 iterations is 7.765901489673278e-05\n",
      "Cost at 750000 iterations is 7.745815818584156e-05\n",
      "Cost at 755000 iterations is 7.725880696832254e-05\n",
      "Cost at 760000 iterations is 7.70609312401842e-05\n",
      "Cost at 765000 iterations is 7.686450172612488e-05\n",
      "Cost at 770000 iterations is 7.666948985962508e-05\n",
      "Cost at 775000 iterations is 7.647586776365869e-05\n",
      "Cost at 780000 iterations is 7.62836082320184e-05\n",
      "Cost at 785000 iterations is 7.609268471120487e-05\n",
      "Cost at 790000 iterations is 7.590307128290457e-05\n",
      "Cost at 795000 iterations is 7.571474264698369e-05\n",
      "Cost at 800000 iterations is 7.552767410503191e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at 805000 iterations is 7.534184154439487e-05\n",
      "Cost at 810000 iterations is 7.515722142271164e-05\n",
      "Cost at 815000 iterations is 7.4973790752915e-05\n",
      "Cost at 820000 iterations is 7.479152708870009e-05\n",
      "Cost at 825000 iterations is 7.461040851042712e-05\n",
      "Cost at 830000 iterations is 7.443041361145622e-05\n",
      "Cost at 835000 iterations is 7.425152148489494e-05\n",
      "Cost at 840000 iterations is 7.40737117107381e-05\n",
      "Cost at 845000 iterations is 7.389696434340598e-05\n",
      "Cost at 850000 iterations is 7.372125989964252e-05\n",
      "Cost at 855000 iterations is 7.354657934677433e-05\n",
      "Cost at 860000 iterations is 7.337290409132785e-05\n",
      "Cost at 865000 iterations is 7.32002159679687e-05\n",
      "Cost at 870000 iterations is 7.302849722876674e-05\n",
      "Cost at 875000 iterations is 7.285773053278701e-05\n",
      "Cost at 880000 iterations is 7.268789893596247e-05\n",
      "Cost at 885000 iterations is 7.251898588127602e-05\n",
      "Cost at 890000 iterations is 7.235097518921625e-05\n",
      "Cost at 895000 iterations is 7.21838510485032e-05\n",
      "Cost at 900000 iterations is 7.201759800708675e-05\n",
      "Cost at 905000 iterations is 7.185220096338934e-05\n",
      "Cost at 910000 iterations is 7.168764515780331e-05\n",
      "Cost at 915000 iterations is 7.152391616441384e-05\n",
      "Cost at 920000 iterations is 7.136099988296483e-05\n",
      "Cost at 925000 iterations is 7.119888253103808e-05\n",
      "Cost at 930000 iterations is 7.103755063644832e-05\n",
      "Cost at 935000 iterations is 7.087699102985096e-05\n",
      "Cost at 940000 iterations is 7.071719083753613e-05\n",
      "Cost at 945000 iterations is 7.055813747443891e-05\n",
      "Cost at 950000 iterations is 7.039981863731653e-05\n",
      "Cost at 955000 iterations is 7.02422222981156e-05\n",
      "Cost at 960000 iterations is 7.008533669751796e-05\n",
      "Cost at 965000 iterations is 6.992915033865052e-05\n",
      "Cost at 970000 iterations is 6.977365198096413e-05\n",
      "Cost at 975000 iterations is 6.96188306342672e-05\n",
      "Cost at 980000 iterations is 6.94646755529197e-05\n",
      "Cost at 985000 iterations is 6.931117623017107e-05\n",
      "Cost at 990000 iterations is 6.91583223926456e-05\n",
      "Cost at 995000 iterations is 6.900610399496728e-05\n",
      "Cost at 1000000 iterations is 6.885451121452243e-05\n",
      "Cost at 1005000 iterations is 6.870353444635177e-05\n",
      "Cost at 1010000 iterations is 6.855316429817201e-05\n",
      "Cost at 1015000 iterations is 6.840339158552353e-05\n",
      "Cost at 1020000 iterations is 6.825420732703083e-05\n",
      "Cost at 1025000 iterations is 6.810560273978817e-05\n",
      "Cost at 1030000 iterations is 6.79575692348583e-05\n",
      "Cost at 1035000 iterations is 6.781009841287455e-05\n",
      "Cost at 1040000 iterations is 6.766318205975371e-05\n",
      "Cost at 1045000 iterations is 6.751681214251904e-05\n",
      "Cost at 1050000 iterations is 6.737098080521363e-05\n",
      "Cost at 1055000 iterations is 6.722568036492e-05\n",
      "Cost at 1060000 iterations is 6.708090330786793e-05\n",
      "Cost at 1065000 iterations is 6.693664228564738e-05\n",
      "Cost at 1070000 iterations is 6.679289011149632e-05\n",
      "Cost at 1075000 iterations is 6.664963975669061e-05\n",
      "Cost at 1080000 iterations is 6.650688434701286e-05\n",
      "Cost at 1085000 iterations is 6.636461715930103e-05\n",
      "Cost at 1090000 iterations is 6.622283161808645e-05\n",
      "Cost at 1095000 iterations is 6.608152129230908e-05\n",
      "Cost at 1100000 iterations is 6.594067989210533e-05\n",
      "Cost at 1105000 iterations is 6.58003012656746e-05\n",
      "Cost at 1110000 iterations is 6.566037939622026e-05\n",
      "Cost at 1115000 iterations is 6.552090839895915e-05\n",
      "Cost at 1120000 iterations is 6.538188251820369e-05\n",
      "Cost at 1125000 iterations is 6.5243296124509e-05\n",
      "Cost at 1130000 iterations is 6.510514371189332e-05\n",
      "Cost at 1135000 iterations is 6.49674198951123e-05\n",
      "Cost at 1140000 iterations is 6.483011940700554e-05\n",
      "Cost at 1145000 iterations is 6.469323709590298e-05\n",
      "Cost at 1150000 iterations is 6.455676792308928e-05\n",
      "Cost at 1155000 iterations is 6.442070696033178e-05\n",
      "Cost at 1160000 iterations is 6.428504938745776e-05\n",
      "Cost at 1165000 iterations is 6.414979048999922e-05\n",
      "Cost at 1170000 iterations is 6.401492565688145e-05\n",
      "Cost at 1175000 iterations is 6.388045037817748e-05\n",
      "Cost at 1180000 iterations is 6.374636024290244e-05\n",
      "Cost at 1185000 iterations is 6.36126509368642e-05\n",
      "Cost at 1190000 iterations is 6.347931824057408e-05\n",
      "Cost at 1195000 iterations is 6.334635802718616e-05\n",
      "Cost at 1200000 iterations is 6.321376626050629e-05\n",
      "Cost at 1205000 iterations is 6.30815389930304e-05\n",
      "Cost at 1210000 iterations is 6.294967236404112e-05\n",
      "Cost at 1215000 iterations is 6.281816259774055e-05\n",
      "Cost at 1220000 iterations is 6.268700600143351e-05\n",
      "Cost at 1225000 iterations is 6.255619896374635e-05\n",
      "Cost at 1230000 iterations is 6.24257379528975e-05\n",
      "Cost at 1235000 iterations is 6.229561951499943e-05\n",
      "Cost at 1240000 iterations is 6.21658402724043e-05\n",
      "Cost at 1245000 iterations is 6.203639692209037e-05\n",
      "Cost at 1250000 iterations is 6.190728623408278e-05\n",
      "Cost at 1255000 iterations is 6.17785050499179e-05\n",
      "Cost at 1260000 iterations is 6.16500502811356e-05\n",
      "Cost at 1265000 iterations is 6.152191890781377e-05\n",
      "Cost at 1270000 iterations is 6.13941079771344e-05\n",
      "Cost at 1275000 iterations is 6.12666146019877e-05\n",
      "Cost at 1280000 iterations is 6.113943595960113e-05\n",
      "Cost at 1285000 iterations is 6.101256929021105e-05\n",
      "Cost at 1290000 iterations is 6.088601189575769e-05\n",
      "Cost at 1295000 iterations is 6.075976113861634e-05\n",
      "Cost at 1300000 iterations is 6.063381444035231e-05\n",
      "Cost at 1305000 iterations is 6.050816928051889e-05\n",
      "Cost at 1310000 iterations is 6.038282319546155e-05\n",
      "Cost at 1315000 iterations is 6.025777377717291e-05\n",
      "Cost at 1320000 iterations is 6.0133018672161895e-05\n",
      "Cost at 1325000 iterations is 6.000855558035061e-05\n",
      "Cost at 1330000 iterations is 5.988438225400317e-05\n",
      "Cost at 1335000 iterations is 5.976049649667084e-05\n",
      "Cost at 1340000 iterations is 5.9636896162172387e-05\n",
      "Cost at 1345000 iterations is 5.951357915358484e-05\n",
      "Cost at 1350000 iterations is 5.9390543422272105e-05\n",
      "Cost at 1355000 iterations is 5.926778696692388e-05\n",
      "Cost at 1360000 iterations is 5.9145307832626736e-05\n",
      "Cost at 1365000 iterations is 5.902310410994703e-05\n",
      "Cost at 1370000 iterations is 5.890117393404201e-05\n",
      "Cost at 1375000 iterations is 5.87795154837884e-05\n",
      "Cost at 1380000 iterations is 5.865812698093088e-05\n",
      "Cost at 1385000 iterations is 5.853700668925008e-05\n",
      "Cost at 1390000 iterations is 5.841615291374558e-05\n",
      "Cost at 1395000 iterations is 5.829556399984369e-05\n",
      "Cost at 1400000 iterations is 5.817523833261896e-05\n",
      "Cost at 1405000 iterations is 5.8055174336031084e-05\n",
      "Cost at 1410000 iterations is 5.7935370472181395e-05\n",
      "Cost at 1415000 iterations is 5.781582524058231e-05\n",
      "Cost at 1420000 iterations is 5.769653717744846e-05\n",
      "Cost at 1425000 iterations is 5.7577504854992814e-05\n",
      "Cost at 1430000 iterations is 5.745872688074612e-05\n",
      "Cost at 1435000 iterations is 5.7340201896888784e-05\n",
      "Cost at 1440000 iterations is 5.722192857959315e-05\n",
      "Cost at 1445000 iterations is 5.710390563837989e-05\n",
      "Cost at 1450000 iterations is 5.698613181549234e-05\n",
      "Cost at 1455000 iterations is 5.6868605885274974e-05\n",
      "Cost at 1460000 iterations is 5.675132665357263e-05\n",
      "Cost at 1465000 iterations is 5.66342929571325e-05\n",
      "Cost at 1470000 iterations is 5.65175036630258e-05\n",
      "Cost at 1475000 iterations is 5.640095766807496e-05\n",
      "Cost at 1480000 iterations is 5.628465389829158e-05\n",
      "Cost at 1485000 iterations is 5.616859130833024e-05\n",
      "Cost at 1490000 iterations is 5.605276888094084e-05\n",
      "Cost at 1495000 iterations is 5.593718562644883e-05\n",
      "Cost at 1500000 iterations is 5.582184058221741e-05\n",
      "Cost at 1505000 iterations is 5.570673281215261e-05\n",
      "Cost at 1510000 iterations is 5.5591861406183976e-05\n",
      "Cost at 1515000 iterations is 5.547722547977868e-05\n",
      "Cost at 1520000 iterations is 5.536282417344991e-05\n",
      "Cost at 1525000 iterations is 5.524865665227501e-05\n",
      "Cost at 1530000 iterations is 5.5134722105426504e-05\n",
      "Cost at 1535000 iterations is 5.50210197457076e-05\n",
      "Cost at 1540000 iterations is 5.490754880909096e-05\n",
      "Cost at 1545000 iterations is 5.479430855426742e-05\n",
      "Cost at 1550000 iterations is 5.468129826220771e-05\n",
      "Cost at 1555000 iterations is 5.456851723571454e-05\n",
      "Cost at 1560000 iterations is 5.4455964798998796e-05\n",
      "Cost at 1565000 iterations is 5.434364029725072e-05\n",
      "Cost at 1570000 iterations is 5.42315430962202e-05\n",
      "Cost at 1575000 iterations is 5.411967258180045e-05\n",
      "Cost at 1580000 iterations is 5.400802815962257e-05\n",
      "Cost at 1585000 iterations is 5.389660925464813e-05\n",
      "Cost at 1590000 iterations is 5.378541531077402e-05\n",
      "Cost at 1595000 iterations is 5.367444579043788e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at 1600000 iterations is 5.356370017422795e-05\n",
      "Cost at 1605000 iterations is 5.345317796050221e-05\n",
      "Cost at 1610000 iterations is 5.334287866500736e-05\n",
      "Cost at 1615000 iterations is 5.3232801820503854e-05\n",
      "Cost at 1620000 iterations is 5.3122946976396364e-05\n",
      "Cost at 1625000 iterations is 5.30133136983677e-05\n",
      "Cost at 1630000 iterations is 5.29039015680184e-05\n",
      "Cost at 1635000 iterations is 5.27947101825049e-05\n",
      "Cost at 1640000 iterations is 5.2685739154190045e-05\n",
      "Cost at 1645000 iterations is 5.257698811029262e-05\n",
      "Cost at 1650000 iterations is 5.246845669254057e-05\n",
      "Cost at 1655000 iterations is 5.236014455682537e-05\n",
      "Cost at 1660000 iterations is 5.225205137287194e-05\n",
      "Cost at 1665000 iterations is 5.214417682389543e-05\n",
      "Cost at 1670000 iterations is 5.203652060627612e-05\n",
      "Cost at 1675000 iterations is 5.1929082429228194e-05\n",
      "Cost at 1680000 iterations is 5.182186201447692e-05\n",
      "Cost at 1685000 iterations is 5.1714859095936323e-05\n",
      "Cost at 1690000 iterations is 5.160807341939642e-05\n",
      "Cost at 1695000 iterations is 5.150150474220291e-05\n",
      "Cost at 1700000 iterations is 5.1395152832952536e-05\n",
      "Cost at 1705000 iterations is 5.128901747118184e-05\n",
      "Cost at 1710000 iterations is 5.118309844706725e-05\n",
      "Cost at 1715000 iterations is 5.107739556111687e-05\n",
      "Cost at 1720000 iterations is 5.097190862388468e-05\n",
      "Cost at 1725000 iterations is 5.086663745566492e-05\n",
      "Cost at 1730000 iterations is 5.0761581886208784e-05\n",
      "Cost at 1735000 iterations is 5.06567417544333e-05\n",
      "Cost at 1740000 iterations is 5.0552116908137705e-05\n",
      "Cost at 1745000 iterations is 5.044770720372141e-05\n",
      "Cost at 1750000 iterations is 5.0343512505909526e-05\n",
      "Cost at 1755000 iterations is 5.0239532687473265e-05\n",
      "Cost at 1760000 iterations is 5.0135767628959583e-05\n",
      "Cost at 1765000 iterations is 5.003221721842413e-05\n",
      "Cost at 1770000 iterations is 4.9928881351165545e-05\n",
      "Cost at 1775000 iterations is 4.9825759929462034e-05\n",
      "Cost at 1780000 iterations is 4.972285286231413e-05\n",
      "Cost at 1785000 iterations is 4.962016006518934e-05\n",
      "Cost at 1790000 iterations is 4.9517681459765686e-05\n",
      "Cost at 1795000 iterations is 4.941541697368972e-05\n",
      "Cost at 1800000 iterations is 4.93133665403232e-05\n",
      "Cost at 1805000 iterations is 4.9211530098505504e-05\n",
      "Cost at 1810000 iterations is 4.910990759231062e-05\n",
      "Cost at 1815000 iterations is 4.900849897081394e-05\n",
      "Cost at 1820000 iterations is 4.890730418785778e-05\n",
      "Cost at 1825000 iterations is 4.880632320182018e-05\n",
      "Cost at 1830000 iterations is 4.8705555975392375e-05\n",
      "Cost at 1835000 iterations is 4.8605002475352286e-05\n",
      "Cost at 1840000 iterations is 4.850466267234531e-05\n",
      "Cost at 1845000 iterations is 4.8404536540671836e-05\n",
      "Cost at 1850000 iterations is 4.830462405806607e-05\n",
      "Cost at 1855000 iterations is 4.820492520549493e-05\n",
      "Cost at 1860000 iterations is 4.810543996694576e-05\n",
      "Cost at 1865000 iterations is 4.800616832922552e-05\n",
      "Cost at 1870000 iterations is 4.7907110281761324e-05\n",
      "Cost at 1875000 iterations is 4.780826581640211e-05\n",
      "Cost at 1880000 iterations is 4.7709634927228395e-05\n",
      "Cost at 1885000 iterations is 4.761121761035977e-05\n",
      "Cost at 1890000 iterations is 4.751301386377046e-05\n",
      "Cost at 1895000 iterations is 4.741502368710668e-05\n",
      "Cost at 1900000 iterations is 4.7317247081505735e-05\n",
      "Cost at 1905000 iterations is 4.721968404941955e-05\n",
      "Cost at 1910000 iterations is 4.71223345944462e-05\n",
      "Cost at 1915000 iterations is 4.7025198721153924e-05\n",
      "Cost at 1920000 iterations is 4.692827643491939e-05\n",
      "Cost at 1925000 iterations is 4.6831567741767776e-05\n",
      "Cost at 1930000 iterations is 4.673507264820459e-05\n",
      "Cost at 1935000 iterations is 4.663879116106866e-05\n",
      "Cost at 1940000 iterations is 4.654272328737569e-05\n",
      "Cost at 1945000 iterations is 4.6446869034171246e-05\n",
      "Cost at 1950000 iterations is 4.635122840837888e-05\n",
      "Cost at 1955000 iterations is 4.625580141666879e-05\n",
      "Cost at 1960000 iterations is 4.616058806530566e-05\n",
      "Cost at 1965000 iterations is 4.606558836002501e-05\n",
      "Cost at 1970000 iterations is 4.597080230589161e-05\n",
      "Cost at 1975000 iterations is 4.587622990717508e-05\n",
      "Cost at 1980000 iterations is 4.5781871167223715e-05\n",
      "Cost at 1985000 iterations is 4.5687726088339354e-05\n",
      "Cost at 1990000 iterations is 4.55937946716603e-05\n",
      "Cost at 1995000 iterations is 4.550007691704492e-05\n",
      "Cost at 1999999 iterations is 4.540659150241295e-05\n"
     ]
    }
   ],
   "source": [
    "net = NeuralNet() \n",
    "\n",
    "#train neural net on examples of the form <x/90, sin(x)> where x ranges from 0 to 90.\n",
    "X = np.array([ \n",
    "    [0], [5], [10], [14], [21], [27], [31], [39], [45], [49], [58], [60], [70], [74], [79], [82], [90]\n",
    "   ]) \n",
    "\n",
    "y = np.array([[0, 0.087, 0.1736, 0.2419, 0.3583, 0.4539, 0.515, 0.6293, 0.7071, 0.7547, 0.848, 0.866, 0.9396, 0.9612, 0.9816, 0.9902, 1]]) \n",
    "\n",
    "net.train(X/90, y, regularization=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sin(0) = 0.0\n",
      "predicted_sin(0) = [[0.03739954]]\n",
      "sin(1) = 0.01745240643728351\n",
      "predicted_sin(1) = [[0.0444105]]\n",
      "sin(2) = 0.03489949670250097\n",
      "predicted_sin(2) = [[0.05251426]]\n",
      "sin(3) = 0.052335956242943835\n",
      "predicted_sin(3) = [[0.06178584]]\n",
      "sin(4) = 0.0697564737441253\n",
      "predicted_sin(4) = [[0.07227841]]\n",
      "sin(5) = 0.08715574274765817\n",
      "predicted_sin(5) = [[0.08401768]]\n",
      "sin(6) = 0.10452846326765347\n",
      "predicted_sin(6) = [[0.09699745]]\n",
      "sin(7) = 0.12186934340514748\n",
      "predicted_sin(7) = [[0.11117733]]\n",
      "sin(8) = 0.13917310096006544\n",
      "predicted_sin(8) = [[0.12648283]]\n",
      "sin(9) = 0.15643446504023087\n",
      "predicted_sin(9) = [[0.14280798]]\n",
      "sin(10) = 0.17364817766693033\n",
      "predicted_sin(10) = [[0.16002036]]\n",
      "sin(11) = 0.1908089953765448\n",
      "predicted_sin(11) = [[0.17796792]]\n",
      "sin(12) = 0.20791169081775934\n",
      "predicted_sin(12) = [[0.19648685]]\n",
      "sin(13) = 0.224951054343865\n",
      "predicted_sin(13) = [[0.21540984]]\n",
      "sin(14) = 0.24192189559966773\n",
      "predicted_sin(14) = [[0.23457363]]\n",
      "sin(15) = 0.25881904510252074\n",
      "predicted_sin(15) = [[0.25382566]]\n",
      "sin(16) = 0.27563735581699916\n",
      "predicted_sin(16) = [[0.27302903]]\n",
      "sin(17) = 0.29237170472273677\n",
      "predicted_sin(17) = [[0.29206597]]\n",
      "sin(18) = 0.3090169943749474\n",
      "predicted_sin(18) = [[0.31083955]]\n",
      "sin(19) = 0.3255681544571567\n",
      "predicted_sin(19) = [[0.32927409]]\n",
      "sin(20) = 0.3420201433256687\n",
      "predicted_sin(20) = [[0.34731441]]\n",
      "sin(21) = 0.35836794954530027\n",
      "predicted_sin(21) = [[0.36492418]]\n",
      "sin(22) = 0.374606593415912\n",
      "predicted_sin(22) = [[0.38208385]]\n",
      "sin(23) = 0.39073112848927377\n",
      "predicted_sin(23) = [[0.39878823]]\n",
      "sin(24) = 0.4067366430758002\n",
      "predicted_sin(24) = [[0.41504401]]\n",
      "sin(25) = 0.42261826174069944\n",
      "predicted_sin(25) = [[0.43086738]]\n",
      "sin(26) = 0.4383711467890774\n",
      "predicted_sin(26) = [[0.4462818]]\n",
      "sin(27) = 0.45399049973954675\n",
      "predicted_sin(27) = [[0.461316]]\n",
      "sin(28) = 0.4694715627858908\n",
      "predicted_sin(28) = [[0.47600221]]\n",
      "sin(29) = 0.48480962024633706\n",
      "predicted_sin(29) = [[0.49037474]]\n",
      "sin(30) = 0.49999999999999994\n",
      "predicted_sin(30) = [[0.50446863]]\n",
      "sin(31) = 0.5150380749100542\n",
      "predicted_sin(31) = [[0.51831869]]\n",
      "sin(32) = 0.5299192642332049\n",
      "predicted_sin(32) = [[0.53195863]]\n",
      "sin(33) = 0.5446390350150271\n",
      "predicted_sin(33) = [[0.54542041]]\n",
      "sin(34) = 0.5591929034707469\n",
      "predicted_sin(34) = [[0.55873363]]\n",
      "sin(35) = 0.573576436351046\n",
      "predicted_sin(35) = [[0.57192518]]\n",
      "sin(36) = 0.5877852522924731\n",
      "predicted_sin(36) = [[0.58501889]]\n",
      "sin(37) = 0.6018150231520483\n",
      "predicted_sin(37) = [[0.59803525]]\n",
      "sin(38) = 0.6156614753256583\n",
      "predicted_sin(38) = [[0.61099125]]\n",
      "sin(39) = 0.6293203910498374\n",
      "predicted_sin(39) = [[0.62390024]]\n",
      "sin(40) = 0.6427876096865393\n",
      "predicted_sin(40) = [[0.63677184]]\n",
      "sin(41) = 0.6560590289905073\n",
      "predicted_sin(41) = [[0.64961192]]\n",
      "sin(42) = 0.6691306063588582\n",
      "predicted_sin(42) = [[0.66242258]]\n",
      "sin(43) = 0.6819983600624985\n",
      "predicted_sin(43) = [[0.67520221]]\n",
      "sin(44) = 0.6946583704589973\n",
      "predicted_sin(44) = [[0.68794554]]\n",
      "sin(45) = 0.7071067811865476\n",
      "predicted_sin(45) = [[0.70064382]]\n",
      "sin(46) = 0.7193398003386512\n",
      "predicted_sin(46) = [[0.71328494]]\n",
      "sin(47) = 0.7313537016191705\n",
      "predicted_sin(47) = [[0.72585369]]\n",
      "sin(48) = 0.7431448254773942\n",
      "predicted_sin(48) = [[0.73833198]]\n",
      "sin(49) = 0.754709580222772\n",
      "predicted_sin(49) = [[0.75069921]]\n",
      "sin(50) = 0.766044443118978\n",
      "predicted_sin(50) = [[0.76293258]]\n",
      "sin(51) = 0.7771459614569709\n",
      "predicted_sin(51) = [[0.77500751]]\n",
      "sin(52) = 0.788010753606722\n",
      "predicted_sin(52) = [[0.78689811]]\n",
      "sin(53) = 0.7986355100472928\n",
      "predicted_sin(53) = [[0.7985776]]\n",
      "sin(54) = 0.8090169943749475\n",
      "predicted_sin(54) = [[0.81001885]]\n",
      "sin(55) = 0.8191520442889918\n",
      "predicted_sin(55) = [[0.8211949]]\n",
      "sin(56) = 0.8290375725550417\n",
      "predicted_sin(56) = [[0.83207944]]\n",
      "sin(57) = 0.838670567945424\n",
      "predicted_sin(57) = [[0.8426473]]\n",
      "sin(58) = 0.8480480961564261\n",
      "predicted_sin(58) = [[0.85287498]]\n",
      "sin(59) = 0.8571673007021123\n",
      "predicted_sin(59) = [[0.86274104]]\n",
      "sin(60) = 0.8660254037844386\n",
      "predicted_sin(60) = [[0.8722265]]\n",
      "sin(61) = 0.8746197071393957\n",
      "predicted_sin(61) = [[0.88131515]]\n",
      "sin(62) = 0.8829475928589269\n",
      "predicted_sin(62) = [[0.88999384]]\n",
      "sin(63) = 0.8910065241883678\n",
      "predicted_sin(63) = [[0.8982526]]\n",
      "sin(64) = 0.898794046299167\n",
      "predicted_sin(64) = [[0.90608479]]\n",
      "sin(65) = 0.9063077870366499\n",
      "predicted_sin(65) = [[0.9134871]]\n",
      "sin(66) = 0.9135454576426009\n",
      "predicted_sin(66) = [[0.92045947]]\n",
      "sin(67) = 0.9205048534524404\n",
      "predicted_sin(67) = [[0.927005]]\n",
      "sin(68) = 0.9271838545667874\n",
      "predicted_sin(68) = [[0.93312974]]\n",
      "sin(69) = 0.9335804264972017\n",
      "predicted_sin(69) = [[0.93884245]]\n",
      "sin(70) = 0.9396926207859083\n",
      "predicted_sin(70) = [[0.9441543]]\n",
      "sin(71) = 0.9455185755993167\n",
      "predicted_sin(71) = [[0.94907859]]\n",
      "sin(72) = 0.9510565162951535\n",
      "predicted_sin(72) = [[0.95363038]]\n",
      "sin(73) = 0.9563047559630354\n",
      "predicted_sin(73) = [[0.95782619]]\n",
      "sin(74) = 0.9612616959383189\n",
      "predicted_sin(74) = [[0.96168361]]\n",
      "sin(75) = 0.9659258262890683\n",
      "predicted_sin(75) = [[0.96522105]]\n",
      "sin(76) = 0.9702957262759965\n",
      "predicted_sin(76) = [[0.96845735]]\n",
      "sin(77) = 0.9743700647852352\n",
      "predicted_sin(77) = [[0.97141159]]\n",
      "sin(78) = 0.9781476007338056\n",
      "predicted_sin(78) = [[0.97410277]]\n",
      "sin(79) = 0.981627183447664\n",
      "predicted_sin(79) = [[0.97654961]]\n",
      "sin(80) = 0.984807753012208\n",
      "predicted_sin(80) = [[0.97877039]]\n",
      "sin(81) = 0.9876883405951378\n",
      "predicted_sin(81) = [[0.98078277]]\n",
      "sin(82) = 0.9902680687415704\n",
      "predicted_sin(82) = [[0.98260368]]\n",
      "sin(83) = 0.992546151641322\n",
      "predicted_sin(83) = [[0.98424922]]\n",
      "sin(84) = 0.9945218953682733\n",
      "predicted_sin(84) = [[0.98573461]]\n",
      "sin(85) = 0.9961946980917455\n",
      "predicted_sin(85) = [[0.98707413]]\n",
      "sin(86) = 0.9975640502598242\n",
      "predicted_sin(86) = [[0.98828112]]\n",
      "sin(87) = 0.9986295347545738\n",
      "predicted_sin(87) = [[0.98936797]]\n",
      "sin(88) = 0.9993908270190958\n",
      "predicted_sin(88) = [[0.99034611]]\n",
      "sin(89) = 0.9998476951563913\n",
      "predicted_sin(89) = [[0.99122609]]\n",
      "sin(90) = 1.0\n",
      "predicted_sin(90) = [[0.99201756]]\n"
     ]
    }
   ],
   "source": [
    "#Test net on on all values of x where x ranges from 0 to 90. \n",
    "\n",
    "for i in range(0,91):\n",
    "    print(\"sin({0}) = {1}\".format(i,np.sin(np.deg2rad(i))))\n",
    "    print(\"predicted_sin({0}) = {1}\".format(i,net.predict(np.array(i).T/90)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
